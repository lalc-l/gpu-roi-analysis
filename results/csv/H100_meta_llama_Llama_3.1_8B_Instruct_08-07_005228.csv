GPU,Model_Name,Test_Mode,Timestamp,GPU_Count,Memory_Usage_GB,Memory_Utilization_Percent,Peak_Memory_Usage_GB,Training_Tokens_Per_Sec_GPU,Training_MFU_Percent,Inference_Tokens_Per_Sec_GPU,Inference_Latency_Ms_Per_Token,Training_Cost_Per_Million_Tokens,Training_Performance_Per_Dollar,Inference_Cost_Per_Million_Tokens,Inference_Performance_Per_Dollar,Final_Loss,Loss_Convergence,Perplexity_Score,Time_To_Target_Accuracy_Seconds,Cost_To_Target_Accuracy
H100,meta-llama/Llama-3.1-8B-Instruct,False,2025-08-07T00:51:49.062243,1,0,0,0,0,0,258.5285859191929,3.869421366188261,0,0,2.890288590584633,96.10728101085238,0,0,0,0,0
