GPU,Model_Name,Test_Mode,Timestamp,GPU_Count,Memory_Usage_GB,Memory_Utilization_Percent,Peak_Memory_Usage_GB,Training_Tokens_Per_Sec_GPU,Training_MFU_Percent,Inference_Tokens_Per_Sec_GPU,Inference_Latency_Ms_Per_Token,Training_Cost_Per_Million_Tokens,Training_Performance_Per_Dollar,Inference_Cost_Per_Million_Tokens,Inference_Performance_Per_Dollar,Final_Loss,Loss_Convergence,Perplexity_Score,Time_To_Target_Accuracy_Seconds,Cost_To_Target_Accuracy
H100,meta-llama/Llama-3.1-8B-Instruct,False,2025-08-07T01:05:14.708968,1,0,0,0,0,0,258.74458714720663,3.865117724570963,0,0,2.887875763743447,96.18757886513258,0,0,0,0,0
