GPU,Model_Name,Test_Mode,Timestamp,GPU_Count,Memory_Usage_GB,Memory_Utilization_Percent,Peak_Memory_Usage_GB,Training_Tokens_Per_Sec_GPU,Training_MFU_Percent,Inference_Tokens_Per_Sec_GPU,Inference_Latency_Ms_Per_Token,Raw_FLOPS_Per_Second,Model_Parameters,Speedup_vs_Baseline,Eval_Accuracy_Proxy,Training_Cost_Per_Million_Tokens,Training_Performance_Per_Dollar,Inference_Cost_Per_Million_Tokens,Inference_Performance_Per_Dollar,Final_Loss,Loss_Convergence,Perplexity_Score,Time_To_Target_Accuracy_Seconds,Cost_To_Target_Accuracy
H100,meta-llama/Llama-3.1-8B-Instruct,False,08-07_01:34:56,1,0,0,0,0,0,51.3444858707751,19.47681802428431,0,8030261248,1.0,100.0,0,0,14.55311528686541,19.08716946868963,0,0,0,0,0
