GPU,Model_Name,Test_Mode,Timestamp,GPU_Count,Memory_Usage_GB,Memory_Utilization_Percent,Peak_Memory_Usage_GB,Training_Tokens_Per_Sec_GPU,Training_MFU_Percent,Inference_Tokens_Per_Sec_GPU,Inference_Latency_Ms_Per_Token,Raw_FLOPS_Per_Second,Model_Parameters,Speedup_vs_Baseline,Eval_Accuracy_Proxy,Training_Cost_Per_Million_Tokens,Training_Performance_Per_Dollar,Inference_Cost_Per_Million_Tokens,Inference_Performance_Per_Dollar,Final_Loss,Loss_Convergence,Perplexity_Score,Time_To_Target_Accuracy_Seconds,Cost_To_Target_Accuracy
H100,meta-llama/Llama-3.1-8B-Instruct,False,2025-08-07T01:22:09.654422,1,0,0,0,0,0,197.4554922227668,5.0987999679313765,0,8030261248,1.0,100.0,0,0,3.784256461092587,73.40352870734826,0,0,0,0,0
